{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 输入\n",
    "    * feather数据文件\n",
    "    * 模型结构和参数\n",
    "    * 模型权值文件\n",
    "* 输出\n",
    "    * 评估标准"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import comet_ml in the top of your file\n",
    "from comet_ml import Experiment\n",
    "\n",
    "# Add the following code anywhere in your machine learning file\n",
    "experiment = Experiment(api_key=\"Go4XzK6f4G10W9jFaWiHg6JP2\",\n",
    "                        project_name=\"general\", workspace=\"twofyw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context.valid_idx_tile.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from config import *\n",
    "# context = Context('validation', Context.all_columns(), debug=0, mulr=7, fn_feather='tbmData/feather/all_columns-full-30-7.feather')\n",
    "context = Context('validation', Context.all_columns(), debug=0, mulr=1, fn_feather='tbmData/feather/all_columns-full-30-no_noise.feather')\n",
    "# databunch = MultiDeptTabularDataBunch.from_df('tmp', context.cyc_cont, context.dep_var, valid_idx=context.valid_idx_tile, bs=context.valid_idx_tile.shape[0], num_workers=0)\n",
    "databunch = MultiDeptTabularDataBunch.from_df('tmp', context.cyc_cont, context.dep_var, valid_idx=context.valid_idx_tile, bs=500, num_workers=0)\n",
    "\n",
    "preload_pytorch()\n",
    "record = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyc_cont_no = context.cyc_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyc_cont_noise = context.cyc_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyc_cont_no.shape, cyc_cont_noise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cyc_cont_noise.values[:cyc_cont_no.shape[0]] - cyc_cont_no.values).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "    'n_hidden': 100,\n",
    "    'n_layers': 3,\n",
    "    'hidden_p': 0.3,\n",
    "    'input_p': 0.6,\n",
    "    'weight_p': 0.5,\n",
    "    'layers': [3*context.n_cont, 5, 2],\n",
    "    'drops': [0.2] * 3,\n",
    "    'alpha': 2.,\n",
    "    'beta': 1.,\n",
    "    'clip': 0.5,\n",
    "#     'loss_func' = MSELossFlat()\n",
    "    'loss_func': l1\n",
    "}\n",
    "\n",
    "learner = get_cont_model(context, databunch, hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learner.load('rnn-normalized-full-30-s-0-1'); # I believe the input columns of the data this weight was trained on was shuffled (or not shuffled because the new method actually shuffles input)\n",
    "learner.load('all_columns-full-30-7'); # 带噪音数据，correct input columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb,yb = learner.data.one_batch(DatasetType.Valid, detach=False, denorm=False)\n",
    "#     xb,yb = learner.data.one_batch(DatasetType.Train, detach=False, denorm=False)\n",
    "# remove noise\n",
    "# xb = [o[::context.mulr] for o in xb]\n",
    "# yb = yb[::context.mulr]\n",
    "\n",
    "yb = to_detach(yb)\n",
    "cb_handler = CallbackHandler(learner.callbacks) # rnn trainer\n",
    "learner.model.reset()\n",
    "pb, _ = loss_batch(learner.model.eval(), xb, yb, cb_handler=cb_handler)\n",
    "loss, mapd = learner.loss_func(pb, yb), learner.metrics[0](pb, yb)\n",
    "print(mapd)\n",
    "y_np, p_np = (to_np(o) for o in (yb,pb))\n",
    "\n",
    "# Plot p against y. Expect linearity\n",
    "yb_denormed, pb_denormed = denormalize(y_np, *context.stat_y), denormalize(p_np, *context.stat_y)\n",
    "i=0;sns.jointplot(x=yb_denormed[:,i], y=pb_denormed[:,i], kind=\"reg\");\n",
    "i=1;sns.jointplot(x=yb_denormed[:,i], y=pb_denormed[:,i], kind=\"reg\");\n",
    "\n",
    "# reshape x\n",
    "xb_r = to_np(xb[1]).reshape(-1,len(context.cont_names),context.sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load original data\n",
    "fmtr = DataFormatter(context, cycle_feathers=context.fn_cycles)\n",
    "cycles = fmtr.cycles # shorten notation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb_or = context.cyc_cont.values[:,:-2].reshape(context.cyc_cont.shape[0],len(context.cont_names),context.sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.data.valid_ds[i][0].data[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xb = np.array([learner.data.valid_ds[i][0].data[1].numpy() for i in range(5)])\n",
    "# reshape x\n",
    "xb_r = xb.reshape(-1,len(context.cont_names),context.sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 500\n",
    "(xb_r[:i] - xb_or[:i]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem here. The validation samples is not the first few samples of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(learner):\n",
    "    xb,yb = learner.data.one_batch(DatasetType.Valid, detach=False, denorm=False)\n",
    "#     xb,yb = learner.data.one_batch(DatasetType.Train, detach=False, denorm=False)\n",
    "    \n",
    "    yb = to_detach(yb)\n",
    "    cb_handler = CallbackHandler(learner.callbacks) # rnn trainer\n",
    "    learner.model.reset()\n",
    "    pb, _ = loss_batch(learner.model.eval(), xb, yb, cb_handler=cb_handler)\n",
    "    loss, mapd = learner.loss_func(pb, yb), learner.metrics[0](pb, yb)\n",
    "    y_np, p_np = (to_np(o) for o in (yb,pb))\n",
    "    \n",
    "    # Plot p against y. Expect linearity\n",
    "    yb_denormed, pb_denormed = denormalize(y_np, *context.stat_y), denormalize(p_np, *context.stat_y)\n",
    "    i=0;sns.jointplot(x=yb_denormed[:,i], y=pb_denormed[:,i], kind=\"reg\")\n",
    "    i=1;sns.jointplot(x=yb_denormed[:,i], y=pb_denormed[:,i], kind=\"reg\")\n",
    "    \n",
    "    return loss, mapd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, mapd = validate(learner); mapd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare X of different noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct(x, context):\n",
    "    if isinstance(x, Tensor): x = to_np(x)\n",
    "    x = x.reshape(context.sl, len(context.cont_names))\n",
    "    return pd.DataFrame(x, columns=context.cont_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without noise\n",
    "ax = None\n",
    "for i in range(3):\n",
    "    df = reconstruct(xb_np[i], context)\n",
    "    ax = plots(df, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
