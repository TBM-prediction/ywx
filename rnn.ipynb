{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "#init"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import jtplot submodule from jupyterthemes\n",
    "from jupyterthemes import jtplot\n",
    "# currently installed theme will be used to\n",
    "# set plot style if no arguments provided\n",
    "jtplot.style()\n",
    "\n",
    "from preprocessing import *\n",
    "\n",
    "data_path = Path('tbmData/data')\n",
    "fn_txt = sorted(data_path.glob('*.txt'))\n",
    "print(fn_txt[:3])\n",
    "fn_cycles = Path('tbmData/cycles1')\n",
    "\n",
    "debug = True\n",
    "\n",
    "mulr = 3\n",
    "n_cont = 5 if debug else None\n",
    "# num_cycles = 3481\n",
    "num_cycles = 10\n",
    "valid_ratio = 0.2\n",
    "train_ratio = 1 - valid_ratio\n",
    "train_idx = np.arange(int(num_cycles * valid_ratio), num_cycles)\n",
    "valid_idx = np.arange(int(num_cycles * valid_ratio))\n",
    "train_idx_tile = (train_idx[:, None] + np.arange(mulr) * num_cycles).flatten()\n",
    "valid_idx_tile = (valid_idx[:, None] + np.arange(mulr) * num_cycles\n",
    "                  ).flatten()  # take from all tiles\n",
    "\n",
    "bs = 2 if debug else int(num_cycles * train_ratio)\n",
    "gpu_start = 1\n",
    "torch.cuda.set_device(gpu_start)\n",
    "# device_ids = range(gpu_start, gpu_start + num_gpus)\n",
    "\n",
    "# cont_names = ['推进速度', '主驱动1#电机扭矩', '刀盘扭矩', '刀盘转速','主液压油箱温度', '前点偏差X', '主液压油箱温度']\n",
    "is_problem1 = True\n",
    "dep_var = ['推进速度电位器设定值', '刀盘转速电位器设定值'] if is_problem1 else ['总推进力', '刀盘扭矩']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with concurrent.futures.ThreadPoolExecutor() as e:\n",
    "#     cycles = tqdm_notebook(e.map(read_feather_fn, sorted(fn_cycles.glob('cycle*'))[:num_cycles]), desc='read_dataframe', total=num_cycles)\n",
    "#     idx = list(tqdm_notebook(e.map(beginning_index, [o.iloc[:500] for o in cycles]), desc='beginning', total=num_cycles))\n",
    "# #     cont = [o.loc[:,cont_names].iloc[i:i+30] for i, o in zip(idx, cycles)]\n",
    "#     cont = [o.iloc[:,3:].iloc[i:i+30] for i, o in zip(idx, cycles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns_feathers = sorted(fn_cycles.glob('cycle*'))[:num_cycles]\n",
    "fmtr = DataFormatter(cycle_feathers=fns_feathers)\n",
    "cycles = fmtr.cycles\n",
    "idx = [beginning_index(o.iloc[:500]) for o in tqdm_notebook(cycles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_names = [o for o in cycles[0].columns[2:2+n_cont] if o not in dep_var]\n",
    "df_conts = tile_with_noise(cycles, idx, mulr, cont_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cyc = cycles[0].iloc[:500]\n",
    "# axis = plots(get_interesting_columns(cyc), title=str(idx));\n",
    "# for ax in axis.flatten():\n",
    "#     ax.axvline(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deps = fmtr.get_y(dep_var)\n",
    "deps = pd.concat([deps]*mulr).reset_index(drop=True)\n",
    "cyc_cont = flatten_and_cat(df_conts, deps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyc_cont.to_feather('tmp/cyc_cont_all_5c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "=>init"
    ]
   },
   "outputs": [],
   "source": [
    "#init\n",
    "cyc_cont = feather.read_dataframe('tmp/cyc_cont_all_allc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.data import OptTabTfms\n",
    "class MultiDeptTabularDataBunch(DataBunch):\n",
    "    \"Create a `DataBunch` suitable for tabular data.\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_df(cls, path, df:DataFrame, dep_var:str, valid_idx:Collection[int], procs:OptTabTfms=None,\n",
    "                cat_names:OptStrList=None, cont_names:OptStrList=None, classes:Collection=None, \n",
    "                test_df=None, **kwargs)->DataBunch:\n",
    "        \"Create a `DataBunch` from `df` and `valid_idx` with `dep_var`.\"\n",
    "        cat_names = ifnone(cat_names, []).copy()\n",
    "        cont_names = ifnone(cont_names, list(set(df)-set(cat_names)-set(dep_var)))\n",
    "        procs = listify(procs)\n",
    "        src = (TabularList.from_df(df, path=path, cat_names=cat_names, cont_names=cont_names, procs=procs)\n",
    "                           .split_by_idx(valid_idx))\n",
    "        src = src.label_from_df(cols=dep_var) if classes is None else src.label_from_df(cols=dep_var, classes=classes)\n",
    "        if test_df is not None: src.add_test(TabularList.from_df(test_df, cat_names=cat_names, cont_names=cont_names,\n",
    "                                                                 processor = src.train.x.processor))\n",
    "        return src.databunch(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_idx_tile = (valid_idx[:,None] + np.arange(mulr) * num_cycles).flatten() # take from all tiles\n",
    "procs = Normalize\n",
    "databunch = MultiDeptTabularDataBunch.from_df('tmp', cyc_cont, dep_var, valid_idx=valid_idx, bs=bs, procs=procs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ni(it): return next(iter(it))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, v = databunch.train_ds, databunch.valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNDataBunch(DataBunch):\n",
    "    \"Create a `TextDataBunch` suitable for training a language model.\"\n",
    "    @classmethod\n",
    "    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', no_check:bool=False, bs=64, num_workers:int=0,\n",
    "               device:torch.device=None, collate_fn:Callable=data_collate, dl_tfms:Optional[Collection[Callable]]=None, \n",
    "               **kwargs) -> DataBunch:\n",
    "        \"Create a `TextDataBunch` in `path` from the `datasets` for language modelling.\"\n",
    "        datasets = cls._init_ds(train_ds, valid_ds, test_ds)\n",
    "#         datasets = [LanguageModelPreLoader(ds, shuffle=(i==0), bs=bs, **kwargs) for i,ds in enumerate(datasets)]\n",
    "        val_bs = bs\n",
    "        dls = [DataLoader(d, b, shuffle=False) for d,b in zip(datasets, (bs,val_bs,val_bs,val_bs)) if d is not None]\n",
    "        return cls(*dls, path=path, device=device, dl_tfms=dl_tfms, collate_fn=collate_fn, no_check=no_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnndb = RNNDataBunch.create(t, v, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = ni(rnndb.train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define rnn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContModel1(RNNCore):\n",
    "    def __init__(self, n_cat:int, n_cont:int, n_hid:int, n_layers:int, sl=30, \n",
    "                 bidir:bool=False, hidden_p:float=0.2, input_p:float=0.6, \n",
    "                 embed_p:float=0.1, weight_p:float=0.5, qrnn:bool=False):\n",
    "        vocab_sz,pad_token=1,0 # continuous variables only for this model\n",
    "        self.sl, self.n_cat, self.n_cont = sl, n_cat, n_cont\n",
    "        \n",
    "        super().__init__(vocab_sz=vocab_sz, emb_sz=n_cont, n_hid=n_hid, n_layers=n_layers, pad_token=pad_token, bidir=bidir,\n",
    "                 hidden_p=hidden_p, input_p=input_p, embed_p=embed_p, weight_p=weight_p, qrnn=qrnn)\n",
    "        \n",
    "    def forward(self, x)->Tuple[Tensor,Tensor]:\n",
    "        x_cat, x_cont = x[:,self.n_cat], x[:,self.n_cat:]\n",
    "        bs,_ = x_cont.size()\n",
    "        input = x_cont.view(bs, self.sl, self.n_cont)\n",
    "        \n",
    "        if bs!=self.bs:\n",
    "            self.bs=bs\n",
    "            self.reset()\n",
    "        raw_output = self.input_dp(input)\n",
    "        new_hidden,raw_outputs,outputs = [],[],[]\n",
    "        for l, (rnn,hid_dp) in enumerate(zip(self.rnns, self.hidden_dps)):\n",
    "            raw_output, new_h = rnn(raw_output, self.hidden[l])\n",
    "            new_hidden.append(new_h)\n",
    "            raw_outputs.append(raw_output)\n",
    "            if l != self.n_layers - 1: raw_output = hid_dp(raw_output)\n",
    "            outputs.append(raw_output)\n",
    "        self.hidden = to_detach(new_hidden, cpu=False)\n",
    "        return raw_outputs, outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden, n_layers = 20, 6\n",
    "rnn_enc = ContModel1(1, n_cont, n_hidden, n_layers)\n",
    "\n",
    "class MultiInputSequentialRNN(nn.Sequential):\n",
    "    \"A sequential module that passes the reset call to its children.\"\n",
    "    def forward(self, *x):\n",
    "        return super().forward(torch.cat([x[0][:,None].float(), x[1]], 1))\n",
    "        \n",
    "    def reset(self):\n",
    "        for c in self.children():\n",
    "            if hasattr(c, 'reset'): c.reset()\n",
    "                \n",
    "layers, drops = [3*n_cont, 3*n_cont, 2], [0, 0]\n",
    "model = MultiInputSequentialRNN(rnn_enc, PoolingLinearClassifier(layers, drops)).cuda()\n",
    "model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnn_metrics(input, target): \n",
    "    # negate for minimization\n",
    "    # score is best approaching -2\n",
    "    return -our_metrics(input[0], target)\n",
    "learner = Learner(rnndb, model, loss_func=rnn_metrics)\n",
    "learner.model.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit(100, lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, o = model(*x)\n",
    "list(zip(to_np(p), to_np(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_metrics(p, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1(p, y) / y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = tabular_learner(databunch, [5000, 5000, 1000])\n",
    "\n",
    "from fastai.callbacks.tracker import *\n",
    "learner.callback_fns += [ShowGraph, SaveModelCallback]\n",
    "# learner.model = torch.nn.DataParallel(learner.model, device_ids=device_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find()\n",
    "learner.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit_one_cycle(1, 1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find()\n",
    "learner.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit_one_cycle(100, 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find()\n",
    "learner.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit_one_cycle(3, 1e-2/2)\n",
    "learner.recorder.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit_one_cycle(10, 1e-3/2)\n",
    "learner.recorder.plot_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(databunch.valid_dl))\n",
    "y = to_np(y)\n",
    "pred = to_np(learner.pred_batch(x)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = y.max() - y.min()\n",
    "list(zip(pred, y, [(a-b)/(r)*100 for a,b in zip(pred, y)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit_one_cycle(50, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit_one_cycle(100, 2*1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "notify_time": "10",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
