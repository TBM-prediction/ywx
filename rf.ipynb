{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "#init"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import jtplot submodule from jupyterthemes\n",
    "from jupyterthemes import jtplot\n",
    "# currently installed theme will be used to\n",
    "# set plot style if no arguments provided\n",
    "jtplot.style()\n",
    "\n",
    "from preprocessing import *\n",
    "\n",
    "data_path = Path('tbmData/data')\n",
    "fn_txt = sorted(data_path.glob('*.txt'))\n",
    "print(fn_txt[:3])\n",
    "fn_cycles = Path('tbmData/cycles1')\n",
    "\n",
    "mulr = 50\n",
    "num_cycles = 3481\n",
    "# num_cycles = 1000\n",
    "valid_ratio = 0.2\n",
    "train_ratio = 1 - valid_ratio\n",
    "train_idx = np.arange(int(num_cycles * valid_ratio), num_cycles)\n",
    "valid_idx = np.arange(int(num_cycles * valid_ratio))\n",
    "train_idx_tile = (train_idx[:, None] + np.arange(mulr) * num_cycles).flatten()\n",
    "valid_idx_tile = (valid_idx[:, None] + np.arange(mulr) * num_cycles\n",
    "                  ).flatten()  # take from all tiles\n",
    "\n",
    "bs = int(num_cycles * train_ratio)\n",
    "gpu_start = 1\n",
    "num_gpus = 2\n",
    "torch.cuda.set_device(gpu_start)\n",
    "device_ids = range(gpu_start, gpu_start + num_gpus)\n",
    "\n",
    "# cont_names = ['推进速度', '主驱动1#电机扭矩', '刀盘扭矩', '刀盘转速','主液压油箱温度', '前点偏差X', '主液压油箱温度']\n",
    "dep_var = '推进速度电位器设定值'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with concurrent.futures.ThreadPoolExecutor() as e:\n",
    "#     cycles = tqdm_notebook(e.map(read_feather_fn, sorted(fn_cycles.glob('cycle*'))[:num_cycles]), desc='read_dataframe', total=num_cycles)\n",
    "#     idx = list(tqdm_notebook(e.map(beginning_index, [o.iloc[:500] for o in cycles]), desc='beginning', total=num_cycles))\n",
    "# #     cont = [o.loc[:,cont_names].iloc[i:i+30] for i, o in zip(idx, cycles)]\n",
    "#     cont = [o.iloc[:,3:].iloc[i:i+30] for i, o in zip(idx, cycles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns_feathers = sorted(fn_cycles.glob('cycle*'))[:num_cycles]\n",
    "fmtr = DataFormatter(cycle_feathers=fns_feathers)\n",
    "cycles = fmtr.cycles\n",
    "idx = [beginning_index(o.iloc[:500]) for o in tqdm_notebook(cycles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_names = [o for o in cycles[0].columns[2:] if o != dep_var]\n",
    "df_conts = tile_with_noise(cycles, idx, mulr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cyc = cycles[0].iloc[:500]\n",
    "# axis = plots(get_interesting_columns(cyc), title=str(idx));\n",
    "# for ax in axis.flatten():\n",
    "#     ax.axvline(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deps = pd.DataFrame({'桩号': [o['桩号'].iloc[0] for o in cycles]})\n",
    "deps = fmtr.get_y(is_problem1=True).iloc[:,0]\n",
    "deps = pd.Series(np.tile(deps.values, mulr), name=deps.name)\n",
    "cyc_cont = flatten_and_cat(df_conts, deps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyc_cont.to_feather('tmp/cyc_cont_all_allc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "=>init"
    ]
   },
   "outputs": [],
   "source": [
    "cyc_cont = feather.read_dataframe('tmp/cyc_cont_all_5c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val = cyc_cont.iloc[train_idx_tile], cyc_cont.iloc[valid_idx_tile]\n",
    "train_x, train_y = train.drop(columns=dep_var), train.loc[:,dep_var]\n",
    "val_x, val_y = val.drop(columns=dep_var), val.loc[:,dep_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "def set_rf_samples(n):\n",
    "    \"\"\" Changes Scikit learn's random forests to give each tree a random sample of\n",
    "    n random rows.\n",
    "    \"\"\"\n",
    "    forest._generate_sample_indices = (lambda rs, n_samples:\n",
    "        forest.check_random_state(rs).randint(0, n_samples, n))\n",
    "\n",
    "def reset_rf_samples():\n",
    "    \"\"\" Undoes the changes produced by set_rf_samples.\n",
    "    \"\"\"\n",
    "    forest._generate_sample_indices = (lambda rs, n_samples:\n",
    "        forest.check_random_state(rs).randint(0, n_samples, n_samples))\n",
    "    \n",
    "X_train, y_train = train_x, train_y\n",
    "X_valid, y_valid = val_x, val_y\n",
    "def print_score(m):\n",
    "    res = [m.score(X_train, y_train), m.score(X_valid, y_valid)]\n",
    "    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set_rf_samples(000)\n",
    "reset_rf_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_jobs=-1, n_estimators=40, oob_score=False, min_samples_leaf=3, max_features=0.5)\n",
    "m.fit(train_x, train_y)\n",
    "print_score(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_jobs=-1, n_estimators=80, oob_score=True, min_samples_leaf=3)\n",
    "m.fit(train_x, train_y)\n",
    "print(m.score(train_x, train_y), m.score(val_x, val_y), m.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_jobs=-1, n_estimators=40, oob_score=True, min_samples_leaf=3, max_features=0.5)\n",
    "m.fit(train_x, train_y)\n",
    "print(m.score(train_x, train_y), m.score(val_x, val_y), m.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_feat_importance(m, df):\n",
    "    return pd.DataFrame({'cols':df.columns, 'imp':m.feature_importances_}\n",
    "                       ).sort_values('imp', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(m.predict(val_x).tolist(), val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
