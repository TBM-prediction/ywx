{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "#init"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# import jtplot submodule from jupyterthemes\n",
    "from jupyterthemes import jtplot\n",
    "# currently installed theme will be used to\n",
    "# set plot style if no arguments provided\n",
    "jtplot.style()\n",
    "\n",
    "from preprocessing import *\n",
    "from mymodels import *\n",
    "from databunch import *\n",
    "\n",
    "data_path = Path('tbmData/data')\n",
    "fn_txt = sorted(data_path.glob('*.txt'))\n",
    "print(fn_txt[:3])\n",
    "fn_cycles = Path('tbmData/cycles1')\n",
    "\n",
    "debug = False\n",
    "# debug = True\n",
    "\n",
    "mulr = 3 if debug else 7\n",
    "\n",
    "selected_columns = False\n",
    "# selected_columns = True\n",
    "if selected_columns == True:\n",
    "    cont_names = ['推进速度', '主驱动1#电机扭矩', '刀盘扭矩', '刀盘转速','主液压油箱温度', '前点偏差X']\n",
    "    n_cont = len(cont_names)\n",
    "else:\n",
    "    n_cont = 5 if debug else 192\n",
    "    \n",
    "num_cycles = 10 if debug else 3481\n",
    "\n",
    "valid_ratio = 0.2\n",
    "train_ratio = 1 - valid_ratio\n",
    "train_idx = np.arange(int(num_cycles * valid_ratio), num_cycles)\n",
    "valid_idx = np.arange(int(num_cycles * valid_ratio))\n",
    "train_idx_tile = (train_idx[:, None] + np.arange(mulr) * num_cycles).flatten()\n",
    "valid_idx_tile = (valid_idx[:, None] + np.arange(mulr) * num_cycles\n",
    "                  ).flatten()  # take from all tiles\n",
    "\n",
    "bs = int(num_cycles * train_ratio)\n",
    "sl = 30\n",
    "gpu_start = 1\n",
    "torch.cuda.set_device(gpu_start)\n",
    "# device_ids = range(gpu_start, gpu_start + num_gpus)\n",
    "\n",
    "is_problem1 = True\n",
    "dep_var = ['推进速度电位器设定值', '刀盘转速电位器设定值'] if is_problem1 else ['总推进力', '刀盘扭矩']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fns_feathers = sorted(fn_cycles.glob('cycle*'))[:num_cycles]\n",
    "fmtr = DataFormatter(cycle_feathers=fns_feathers)\n",
    "cycles = fmtr.cycles\n",
    "idx = [beginning_index(o.iloc[:500]) for o in tqdm_notebook(cycles)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cont_names = [o for o in cycles[0].columns[2:2+n_cont] if o not in dep_var]\n",
    "# cont_names = [o for o in cycles[0].columns[cont_names] if o not in dep_var]\n",
    "df_conts = tile_with_noise(cycles, idx, mulr, cont_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# cyc = cycles[i].iloc[:500]\n",
    "# axis = plots(get_interesting_columns(cyc), title=str(idx[i]));\n",
    "# for ax in axis.flatten():\n",
    "#     ax.axvline(idx[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deps = fmtr.get_y(dep_var)\n",
    "deps = pd.concat([deps]*mulr).reset_index(drop=True)\n",
    "cyc_cont = flatten_and_cat(df_conts, deps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cyc_cont.to_feather('tmp/cyc_cont_all_6_debug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "=>init"
    ]
   },
   "outputs": [],
   "source": [
    "#init\n",
    "cyc_cont = feather.read_dataframe('tmp/cyc_cont_all_6_debug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "=>init"
    ]
   },
   "outputs": [],
   "source": [
    "#init\n",
    "cyc_cont = feather.read_dataframe('tmp/cyc_cont_all_allc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_idx_tile = (valid_idx[:,None] + np.arange(mulr) * num_cycles).flatten() # take from all tiles\n",
    "procs = Normalize\n",
    "databunch = MultiDeptTabularDataBunch.from_df('tmp', cyc_cont, dep_var, valid_idx=valid_idx, bs=bs, procs=procs)\n",
    "\n",
    "rnndb = RNNDataBunch.create(databunch.train_ds, databunch.valid_ds, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "class DummyContModel1(RNNCore):\n",
    "    def __init__(self, n_cat:int, n_cont:int, n_hid:int, n_layers:int, sl=30,\n",
    "                 bidir:bool=False, hidden_p:float=0.2, input_p:float=0.6,\n",
    "                 embed_p:float=0.1, weight_p:float=0.5, qrnn:bool=False):\n",
    "        vocab_sz,pad_token=1,0 # continuous variables only for this model\n",
    "        self.sl, self.n_cat, self.n_cont = sl, n_cat, n_cont\n",
    "        self.final = bn_drop_lin(n_cont, 2, actn=None)\n",
    "\n",
    "        super().__init__(vocab_sz=vocab_sz, emb_sz=n_cont, n_hid=n_hid, n_layers=n_layers, pad_token=pad_token, bidir=bidir,\n",
    "                 hidden_p=hidden_p, input_p=input_p, embed_p=embed_p, weight_p=weight_p, qrnn=qrnn)\n",
    "\n",
    "    def forward(self, x_cat, x_cont)->Tuple[Tensor,Tensor]:\n",
    "#         x_cat, x_cont = x[:,self.n_cat], x[:,self.n_cat:]\n",
    "#         print(x_cont.shape)\n",
    "        bs,_ = x_cont.size()\n",
    "        input = x_cont.view(bs, self.sl, self.n_cont)\n",
    "        self.reset()\n",
    "\n",
    "        if bs!=self.bs:\n",
    "            self.bs=bs\n",
    "            self.reset()\n",
    "        raw_output = self.input_dp(input)\n",
    "        new_hidden,raw_outputs,outputs = [],[],[]\n",
    "        for l, (rnn,hid_dp) in enumerate(zip(self.rnns, self.hidden_dps)):\n",
    "            raw_output, new_h = rnn(raw_output, self.hidden[l])\n",
    "            new_hidden.append(new_h)\n",
    "            raw_outputs.append(raw_output)\n",
    "            if l != self.n_layers - 1: raw_output = hid_dp(raw_output)\n",
    "            outputs.append(raw_output)\n",
    "        self.hidden = to_detach(new_hidden, cpu=False)\n",
    "\n",
    "        x = raw_output[:,-1]\n",
    "        mid = x.shape[1]\n",
    "        x = torch.cat([x[:,:mid//2].sum(1)[:,None], x[:,mid//2:].sum(1)[:,None]], 1)\n",
    "        \n",
    "        return x, raw_outputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden, n_layers = n_cont*3, 3\n",
    "# n_hidden, n_layers = 10, 2\n",
    "# , input_p=0.6, weight_p=0.2\n",
    "rnn_enc = ContModel1(1, n_cont, n_hidden, n_layers)\n",
    "\n",
    "layers, drops = [3*n_cont, n_cont, 2], [0.1, 0.1]\n",
    "# model = MultiInputSequentialRNN(rnn_enc, DummyModel(layers, drops)).cuda()\n",
    "# model = DummyContModel1(1, n_cont, n_hidden, n_layers)\n",
    "model = MultiInputSequentialRNN(rnn_enc, PoolingLinearClassifier(layers, drops)).cuda()\n",
    "model.reset()\n",
    "\n",
    "weight = cyc_cont[dep_var].max().values\n",
    "weight = torch.tensor(weight[::-1] / weight.max(), dtype=torch.float32).cuda()\n",
    "\n",
    "learner = Learner(rnndb, model, loss_func=weighted_rnn_mse(weight), metrics=rnn_metrics, opt_func=optim.SGD)\n",
    "\n",
    "from fastai.callbacks import *\n",
    "# learner.callback_fns += [ShowGraph, partial(SaveModelCallback, name='rnn0')]\n",
    "learner.callback_fns += [ShowGraph,]\n",
    "learner.callbacks += [TerminateOnNaNCallback()]\n",
    "alpha, beta = 2., 1.\n",
    "learner.callbacks.append(RNNTrainer(learner, sl, alpha=alpha, beta=beta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find(num_it=50)\n",
    "learner.recorder.plot(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit_one_cycle(5, 1e-4*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find(num_it=50)\n",
    "learner.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit_one_cycle(10, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit_one_cycle(20, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.fit_one_cycle(50, 1e-5 / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = ni(learner.data.train_dl)\n",
    "y, p = y.cpu(), learner.model(*x)[0].cpu()\n",
    "y_np, p_np = to_np(y), to_np(p)\n",
    "# our_metrics(y, p), our_metrics_np(y_np, p_np)\n",
    "lf = weighted_rnn_mse(weight.cpu())\n",
    "our_metrics_np(p_np, y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = learner.model(*x)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p[-2][:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l x b x t x h\n",
    "l, b = 0, 0\n",
    "[(float(p[l][b][t].mean()), float(p[l][b][t].std())) for t in range(30)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l x b x t x h\n",
    "l, b, t = 0, 0, 1\n",
    "[(float(p[l][b][t].mean()), float(p[l][b][t].std())) for l in range(n_layers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(y_np.tolist(), p_np.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "notify_time": "10",
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
